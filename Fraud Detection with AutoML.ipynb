{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Overview\n",
    "\n",
    "Fraud detection is one of the most important applications in data science, as the ability to detect fraud helps establish consumer trust and corporate integrity. Not to mention, eliminating fraud would prevent millions, if not billions, of dollars worth of loss and damages.\n",
    "\n",
    "Depending on the data, running classification algorithms like logistic regression and SVM to detect fraud is relatively uncomplicated. There are the usual steps of collecting the data, cleaning it, and then running it through multiple models to obtain the best metric. To save time, automated machine learning programs can iterate through many machine learning and deep learning models to find the one that provides the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, accuracy_score, classification_report, f1_score, recall_score,roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over 280000 entries of data and going through all of that would be very computationally expensive, so lets just take a small sample as the train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the first 50000 entries as training data\n",
    "df[0:50000].to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234463, 31)\n",
      "(344, 31)\n"
     ]
    }
   ],
   "source": [
    "remain_df = df[50000:]\n",
    "\n",
    "print(remain_df[remain_df['Class']==0].shape)\n",
    "print(remain_df[remain_df['Class']==1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape: (688, 31)\n",
      "Not Fraud Cases: 344\n",
      "Fraud Cases 344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279182</th>\n",
       "      <td>168693.0</td>\n",
       "      <td>-2.410025</td>\n",
       "      <td>-1.432871</td>\n",
       "      <td>1.373919</td>\n",
       "      <td>-2.507625</td>\n",
       "      <td>-1.697742</td>\n",
       "      <td>-0.544289</td>\n",
       "      <td>-1.293413</td>\n",
       "      <td>0.849440</td>\n",
       "      <td>-2.024631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044517</td>\n",
       "      <td>-0.026928</td>\n",
       "      <td>-0.232544</td>\n",
       "      <td>-0.100905</td>\n",
       "      <td>0.384982</td>\n",
       "      <td>-0.207308</td>\n",
       "      <td>-0.205183</td>\n",
       "      <td>-0.327786</td>\n",
       "      <td>101.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174434</th>\n",
       "      <td>121911.0</td>\n",
       "      <td>1.693089</td>\n",
       "      <td>-0.557008</td>\n",
       "      <td>-1.805554</td>\n",
       "      <td>0.605396</td>\n",
       "      <td>-0.206261</td>\n",
       "      <td>-1.161832</td>\n",
       "      <td>0.250070</td>\n",
       "      <td>-0.234809</td>\n",
       "      <td>1.194721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157763</td>\n",
       "      <td>-0.617990</td>\n",
       "      <td>0.051895</td>\n",
       "      <td>-0.223845</td>\n",
       "      <td>-0.172443</td>\n",
       "      <td>-0.094935</td>\n",
       "      <td>-0.043064</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>176.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206671</th>\n",
       "      <td>136313.0</td>\n",
       "      <td>2.159707</td>\n",
       "      <td>-0.542620</td>\n",
       "      <td>-2.882846</td>\n",
       "      <td>-0.961864</td>\n",
       "      <td>0.676114</td>\n",
       "      <td>-0.672313</td>\n",
       "      <td>0.138164</td>\n",
       "      <td>-0.292709</td>\n",
       "      <td>-1.015015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287876</td>\n",
       "      <td>0.759384</td>\n",
       "      <td>-0.198479</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.533916</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>-0.073622</td>\n",
       "      <td>-0.056786</td>\n",
       "      <td>62.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108086</th>\n",
       "      <td>70757.0</td>\n",
       "      <td>1.094891</td>\n",
       "      <td>-0.052185</td>\n",
       "      <td>-0.024230</td>\n",
       "      <td>1.255481</td>\n",
       "      <td>0.159614</td>\n",
       "      <td>0.307443</td>\n",
       "      <td>0.115648</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120580</td>\n",
       "      <td>-0.273670</td>\n",
       "      <td>-0.220620</td>\n",
       "      <td>-0.764709</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>-0.266104</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>74.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184653</th>\n",
       "      <td>126327.0</td>\n",
       "      <td>-0.063378</td>\n",
       "      <td>0.129319</td>\n",
       "      <td>1.302245</td>\n",
       "      <td>0.281004</td>\n",
       "      <td>-1.039008</td>\n",
       "      <td>0.252654</td>\n",
       "      <td>-0.367685</td>\n",
       "      <td>0.327396</td>\n",
       "      <td>1.867043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212056</td>\n",
       "      <td>0.940081</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>-0.120481</td>\n",
       "      <td>-0.963518</td>\n",
       "      <td>-0.262713</td>\n",
       "      <td>0.138978</td>\n",
       "      <td>0.150663</td>\n",
       "      <td>70.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "279182  168693.0 -2.410025 -1.432871  1.373919 -2.507625 -1.697742 -0.544289   \n",
       "174434  121911.0  1.693089 -0.557008 -1.805554  0.605396 -0.206261 -1.161832   \n",
       "206671  136313.0  2.159707 -0.542620 -2.882846 -0.961864  0.676114 -0.672313   \n",
       "108086   70757.0  1.094891 -0.052185 -0.024230  1.255481  0.159614  0.307443   \n",
       "184653  126327.0 -0.063378  0.129319  1.302245  0.281004 -1.039008  0.252654   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "279182 -1.293413  0.849440 -2.024631  ...  0.044517 -0.026928 -0.232544   \n",
       "174434  0.250070 -0.234809  1.194721  ... -0.157763 -0.617990  0.051895   \n",
       "206671  0.138164 -0.292709 -1.015015  ...  0.287876  0.759384 -0.198479   \n",
       "108086  0.115648  0.039560  0.394113  ... -0.120580 -0.273670 -0.220620   \n",
       "184653 -0.367685  0.327396  1.867043  ...  0.212056  0.940081  0.036176   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "279182 -0.100905  0.384982 -0.207308 -0.205183 -0.327786  101.96      0  \n",
       "174434 -0.223845 -0.172443 -0.094935 -0.043064  0.004020  176.95      0  \n",
       "206671 -0.002659  0.533916  0.096507 -0.073622 -0.056786   62.59      0  \n",
       "108086 -0.764709  0.738397 -0.266104  0.024003  0.018231   74.89      0  \n",
       "184653 -0.120481 -0.963518 -0.262713  0.138978  0.150663   70.55      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_no_fraud = remain_df[remain_df['Class']==0].sample(344)\n",
    "test_fraud = remain_df[remain_df['Class']==1]\n",
    "\n",
    "test = pd.concat([test_no_fraud, test_fraud])\n",
    "\n",
    "print('Test set shape:', test.shape)\n",
    "print('Not Fraud Cases:', test[test['Class']==0].shape[0])\n",
    "print('Fraud Cases', test[test['Class']==1].shape[0])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 32 columns):\n",
      "Unnamed: 0    50000 non-null int64\n",
      "Time          50000 non-null float64\n",
      "V1            50000 non-null float64\n",
      "V2            50000 non-null float64\n",
      "V3            50000 non-null float64\n",
      "V4            50000 non-null float64\n",
      "V5            50000 non-null float64\n",
      "V6            50000 non-null float64\n",
      "V7            50000 non-null float64\n",
      "V8            50000 non-null float64\n",
      "V9            50000 non-null float64\n",
      "V10           50000 non-null float64\n",
      "V11           50000 non-null float64\n",
      "V12           50000 non-null float64\n",
      "V13           50000 non-null float64\n",
      "V14           50000 non-null float64\n",
      "V15           50000 non-null float64\n",
      "V16           50000 non-null float64\n",
      "V17           50000 non-null float64\n",
      "V18           50000 non-null float64\n",
      "V19           50000 non-null float64\n",
      "V20           50000 non-null float64\n",
      "V21           50000 non-null float64\n",
      "V22           50000 non-null float64\n",
      "V23           50000 non-null float64\n",
      "V24           50000 non-null float64\n",
      "V25           50000 non-null float64\n",
      "V26           50000 non-null float64\n",
      "V27           50000 non-null float64\n",
      "V28           50000 non-null float64\n",
      "Amount        50000 non-null float64\n",
      "Class         50000 non-null int64\n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 12.2 MB\n"
     ]
    }
   ],
   "source": [
    "#provides overview of data types to see if any categorical data needs to be encoded; none here\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Time          0\n",
       "V1            0\n",
       "V2            0\n",
       "V3            0\n",
       "V4            0\n",
       "V5            0\n",
       "V6            0\n",
       "V7            0\n",
       "V8            0\n",
       "V9            0\n",
       "V10           0\n",
       "V11           0\n",
       "V12           0\n",
       "V13           0\n",
       "V14           0\n",
       "V15           0\n",
       "V16           0\n",
       "V17           0\n",
       "V18           0\n",
       "V19           0\n",
       "V20           0\n",
       "V21           0\n",
       "V22           0\n",
       "V23           0\n",
       "V24           0\n",
       "V25           0\n",
       "V26           0\n",
       "V27           0\n",
       "V28           0\n",
       "Amount        0\n",
       "Class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview if any null values are present; none here\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24999.500000</td>\n",
       "      <td>28923.779620</td>\n",
       "      <td>-0.242344</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.692829</td>\n",
       "      <td>0.185482</td>\n",
       "      <td>-0.258043</td>\n",
       "      <td>0.105202</td>\n",
       "      <td>-0.120580</td>\n",
       "      <td>0.053704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028909</td>\n",
       "      <td>-0.106878</td>\n",
       "      <td>-0.039899</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.135912</td>\n",
       "      <td>0.020885</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>93.266587</td>\n",
       "      <td>0.002960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901067</td>\n",
       "      <td>13116.563925</td>\n",
       "      <td>1.887731</td>\n",
       "      <td>1.629766</td>\n",
       "      <td>1.508700</td>\n",
       "      <td>1.400009</td>\n",
       "      <td>1.412611</td>\n",
       "      <td>1.311299</td>\n",
       "      <td>1.282493</td>\n",
       "      <td>1.223824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736011</td>\n",
       "      <td>0.637858</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.594216</td>\n",
       "      <td>0.439013</td>\n",
       "      <td>0.501260</td>\n",
       "      <td>0.388101</td>\n",
       "      <td>0.334785</td>\n",
       "      <td>253.010040</td>\n",
       "      <td>0.054326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-32.965346</td>\n",
       "      <td>-5.172595</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-41.484823</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.262054</td>\n",
       "      <td>-8.593642</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-1.577118</td>\n",
       "      <td>-8.567638</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12499.750000</td>\n",
       "      <td>21893.500000</td>\n",
       "      <td>-0.992599</td>\n",
       "      <td>-0.564348</td>\n",
       "      <td>0.216729</td>\n",
       "      <td>-0.721295</td>\n",
       "      <td>-0.867721</td>\n",
       "      <td>-0.635255</td>\n",
       "      <td>-0.606146</td>\n",
       "      <td>-0.146744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231454</td>\n",
       "      <td>-0.529526</td>\n",
       "      <td>-0.178930</td>\n",
       "      <td>-0.321902</td>\n",
       "      <td>-0.127945</td>\n",
       "      <td>-0.330577</td>\n",
       "      <td>-0.063231</td>\n",
       "      <td>-0.006699</td>\n",
       "      <td>7.627500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24999.500000</td>\n",
       "      <td>33471.500000</td>\n",
       "      <td>-0.245008</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.795902</td>\n",
       "      <td>0.191131</td>\n",
       "      <td>-0.289438</td>\n",
       "      <td>-0.150443</td>\n",
       "      <td>-0.077294</td>\n",
       "      <td>0.058736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068160</td>\n",
       "      <td>-0.082056</td>\n",
       "      <td>-0.051642</td>\n",
       "      <td>0.062302</td>\n",
       "      <td>0.175743</td>\n",
       "      <td>-0.071973</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.022174</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37499.250000</td>\n",
       "      <td>38983.000000</td>\n",
       "      <td>1.155544</td>\n",
       "      <td>0.731591</td>\n",
       "      <td>1.430980</td>\n",
       "      <td>1.067868</td>\n",
       "      <td>0.283011</td>\n",
       "      <td>0.495431</td>\n",
       "      <td>0.423920</td>\n",
       "      <td>0.332187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108087</td>\n",
       "      <td>0.307440</td>\n",
       "      <td>0.078620</td>\n",
       "      <td>0.401568</td>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.300405</td>\n",
       "      <td>0.083875</td>\n",
       "      <td>0.076303</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>44299.000000</td>\n",
       "      <td>1.960497</td>\n",
       "      <td>18.183626</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>5.805795</td>\n",
       "      <td>17.297845</td>\n",
       "      <td>4.014444</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>12910.930000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0          Time            V1            V2            V3  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean   24999.500000  28923.779620     -0.242344      0.010316      0.692829   \n",
       "std    14433.901067  13116.563925      1.887731      1.629766      1.508700   \n",
       "min        0.000000      0.000000    -56.407510    -72.715728    -32.965346   \n",
       "25%    12499.750000  21893.500000     -0.992599     -0.564348      0.216729   \n",
       "50%    24999.500000  33471.500000     -0.245008      0.078253      0.795902   \n",
       "75%    37499.250000  38983.000000      1.155544      0.731591      1.430980   \n",
       "max    49999.000000  44299.000000      1.960497     18.183626      4.101716   \n",
       "\n",
       "                 V4            V5            V6            V7            V8  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.185482     -0.258043      0.105202     -0.120580      0.053704   \n",
       "std        1.400009      1.412611      1.311299      1.282493      1.223824   \n",
       "min       -5.172595    -42.147898    -26.160506    -26.548144    -41.484823   \n",
       "25%       -0.721295     -0.867721     -0.635255     -0.606146     -0.146744   \n",
       "50%        0.191131     -0.289438     -0.150443     -0.077294      0.058736   \n",
       "75%        1.067868      0.283011      0.495431      0.423920      0.332187   \n",
       "max       16.491217     34.801666     22.529298     36.677268     20.007208   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean   ...     -0.028909     -0.106878     -0.039899      0.008362   \n",
       "std    ...      0.736011      0.637858      0.589736      0.594216   \n",
       "min    ...    -20.262054     -8.593642    -26.751119     -2.836627   \n",
       "25%    ...     -0.231454     -0.529526     -0.178930     -0.321902   \n",
       "50%    ...     -0.068160     -0.082056     -0.051642      0.062302   \n",
       "75%    ...      0.108087      0.307440      0.078620      0.401568   \n",
       "max    ...     22.614889      5.805795     17.297845      4.014444   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.135912      0.020885      0.004915      0.004232     93.266587   \n",
       "std        0.439013      0.501260      0.388101      0.334785    253.010040   \n",
       "min       -7.495741     -1.577118     -8.567638     -9.617915      0.000000   \n",
       "25%       -0.127945     -0.330577     -0.063231     -0.006699      7.627500   \n",
       "50%        0.175743     -0.071973      0.009035      0.022174     25.000000   \n",
       "75%        0.422121      0.300405      0.083875      0.076303     85.250000   \n",
       "max        5.525093      3.517346     11.135740     33.847808  12910.930000   \n",
       "\n",
       "              Class  \n",
       "count  50000.000000  \n",
       "mean       0.002960  \n",
       "std        0.054326  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a good way to find placeholder nulls in numerical data. Usually this means looking at the min/max of each feature for any\n",
    "#extremes; data doesn't seem to contain placeholder nulls or outliers\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_fraud = train[train['Class']==0].shape[0]\n",
    "fraud = train[train['Class']==1].shape[0]\n",
    "\n",
    "plt.bar(x=[1,2], height = [fraud, no_fraud], color = ['red', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a great imbalance between fraudulent and non-fraudulent cases, which will affect our algorithms. Therefore, it's necessary to balance these classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Classes with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of ways to balance classes of data. The simplest would be to just oversample the minority class. However, there are other heuristic methods like SMOTE and Adasyn that we can use. In this case, we'll use SMOTE (Synthetic Minority Oversample Technique). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#separate features/target\n",
    "X = train.loc[:, train.columns != 'Class']\n",
    "y = train['Class']\n",
    "\n",
    "#train, test, split \n",
    "os = SMOTE(random_state=117)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=117)\n",
    "\n",
    "#fit SMOTE to training data\n",
    "columns = X_train.columns\n",
    "os_data_X, os_data_y=os.fit_sample(X_train, y_train)\n",
    "\n",
    "#create two dataframes with oversampled data\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  79758\n",
      "Number of not fraud in oversampled data 39879\n",
      "Number of fraud 39879\n",
      "Proportion of not fraud in oversampled data is  0.5\n",
      "Proportion of fraud data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "# Check the numbers\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of not fraud in oversampled data\",len(os_data_y[os_data_y['Class']==0]))\n",
    "print(\"Number of fraud\",len(os_data_y[os_data_y['Class']==1]))\n",
    "print(\"Proportion of not fraud in oversampled data is \",len(os_data_y[os_data_y['Class']==0])/len(os_data_X))\n",
    "print(\"Proportion of fraud data in oversampled data is \",len(os_data_y[os_data_y['Class']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23573</td>\n",
       "      <td>32828.0</td>\n",
       "      <td>0.601467</td>\n",
       "      <td>-0.972097</td>\n",
       "      <td>-0.836823</td>\n",
       "      <td>0.285860</td>\n",
       "      <td>-0.246023</td>\n",
       "      <td>-0.971890</td>\n",
       "      <td>1.018488</td>\n",
       "      <td>-0.529431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168925</td>\n",
       "      <td>-0.323254</td>\n",
       "      <td>-0.505600</td>\n",
       "      <td>0.017159</td>\n",
       "      <td>0.509378</td>\n",
       "      <td>1.056221</td>\n",
       "      <td>-0.181210</td>\n",
       "      <td>0.056364</td>\n",
       "      <td>399.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46656</td>\n",
       "      <td>42873.0</td>\n",
       "      <td>-0.992590</td>\n",
       "      <td>-0.329359</td>\n",
       "      <td>2.326593</td>\n",
       "      <td>-0.695860</td>\n",
       "      <td>0.032342</td>\n",
       "      <td>0.340383</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>0.196443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141609</td>\n",
       "      <td>-0.103302</td>\n",
       "      <td>-0.134270</td>\n",
       "      <td>-0.417595</td>\n",
       "      <td>0.304661</td>\n",
       "      <td>-0.375699</td>\n",
       "      <td>-0.108228</td>\n",
       "      <td>-0.153287</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6358</td>\n",
       "      <td>7577.0</td>\n",
       "      <td>-0.318075</td>\n",
       "      <td>1.062283</td>\n",
       "      <td>1.759506</td>\n",
       "      <td>1.003932</td>\n",
       "      <td>0.426871</td>\n",
       "      <td>0.449983</td>\n",
       "      <td>0.604184</td>\n",
       "      <td>-0.124242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199046</td>\n",
       "      <td>-0.065634</td>\n",
       "      <td>-0.163249</td>\n",
       "      <td>-0.574275</td>\n",
       "      <td>-0.229511</td>\n",
       "      <td>-0.414992</td>\n",
       "      <td>0.214577</td>\n",
       "      <td>-0.031305</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13801</td>\n",
       "      <td>24468.0</td>\n",
       "      <td>-9.970943</td>\n",
       "      <td>-4.156007</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>2.745572</td>\n",
       "      <td>2.812815</td>\n",
       "      <td>-1.567950</td>\n",
       "      <td>1.336645</td>\n",
       "      <td>-2.428785</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.340266</td>\n",
       "      <td>1.091950</td>\n",
       "      <td>3.545291</td>\n",
       "      <td>0.601934</td>\n",
       "      <td>1.824614</td>\n",
       "      <td>0.045613</td>\n",
       "      <td>2.200767</td>\n",
       "      <td>-1.341030</td>\n",
       "      <td>18.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15669</td>\n",
       "      <td>27089.0</td>\n",
       "      <td>-0.413949</td>\n",
       "      <td>1.112684</td>\n",
       "      <td>1.586218</td>\n",
       "      <td>-0.041054</td>\n",
       "      <td>0.026548</td>\n",
       "      <td>-0.881305</td>\n",
       "      <td>0.757186</td>\n",
       "      <td>-0.118384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217986</td>\n",
       "      <td>-0.518803</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>0.386680</td>\n",
       "      <td>-0.162144</td>\n",
       "      <td>0.068418</td>\n",
       "      <td>0.271848</td>\n",
       "      <td>0.122978</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Time        V1        V2        V3        V4        V5  \\\n",
       "0       23573  32828.0  0.601467 -0.972097 -0.836823  0.285860 -0.246023   \n",
       "1       46656  42873.0 -0.992590 -0.329359  2.326593 -0.695860  0.032342   \n",
       "2        6358   7577.0 -0.318075  1.062283  1.759506  1.003932  0.426871   \n",
       "3       13801  24468.0 -9.970943 -4.156007  0.059100  2.745572  2.812815   \n",
       "4       15669  27089.0 -0.413949  1.112684  1.586218 -0.041054  0.026548   \n",
       "\n",
       "         V6        V7        V8  ...       V21       V22       V23       V24  \\\n",
       "0 -0.971890  1.018488 -0.529431  ...  0.168925 -0.323254 -0.505600  0.017159   \n",
       "1  0.340383  0.056838  0.196443  ... -0.141609 -0.103302 -0.134270 -0.417595   \n",
       "2  0.449983  0.604184 -0.124242  ... -0.199046 -0.065634 -0.163249 -0.574275   \n",
       "3 -1.567950  1.336645 -2.428785  ... -3.340266  1.091950  3.545291  0.601934   \n",
       "4 -0.881305  0.757186 -0.118384  ... -0.217986 -0.518803 -0.036909  0.386680   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.509378  1.056221 -0.181210  0.056364  399.00      0  \n",
       "1  0.304661 -0.375699 -0.108228 -0.153287   65.00      0  \n",
       "2 -0.229511 -0.414992  0.214577 -0.031305   36.00      0  \n",
       "3  1.824614  0.045613  2.200767 -1.341030   18.14      0  \n",
       "4 -0.162144  0.068418  0.271848  0.122978    0.89      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the features and target into one dataframe\n",
    "os_train = os_data_X\n",
    "os_train['Class'] = os_data_y.values\n",
    "os_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the classes again to see if it's balanced\n",
    "no_fraud = os_train[os_train['Class']==0].shape[0]\n",
    "fraud = os_train[os_train['Class']==1].shape[0]\n",
    "\n",
    "plt.bar(x=[1,2], height = [fraud, no_fraud], color = ['red', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Oversampling with Balanced Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_train_X = os_train[os_train.columns[2:-1]]\n",
    "os_train_y = os_train['Class']\n",
    "\n",
    "X_test = test[test.columns[1:-1]]\n",
    "y_test = test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = svm.SVC(random_state = 117)\n",
    "dec_tree = tree.DecisionTreeClassifier(random_state = 117)\n",
    "logreg =  LogisticRegression(random_state = 117)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm Accuracy Recall F1 Score ROC AUC\n",
       "0        Decision Tree     0.83   0.68      0.8    0.83\n",
       "1                  SVM     0.88   0.76     0.86    0.88\n",
       "2  Logistic Regression     0.91   0.85     0.91    0.91"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = [dec_tree, support, logreg]\n",
    "classifier_names = ['Decision Tree', 'SVM', 'Logistic Regression']\n",
    "score_array = []\n",
    "\n",
    "for i, clf in enumerate(classifiers):\n",
    "    score_list = []\n",
    "    score_list.append(classifier_names[i])\n",
    "    clf.fit(os_train_X, os_train_y)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    score_list.append(round(accuracy_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(recall_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(f1_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(roc_auc_score(y_test, clf_pred),2))\n",
    "    score_array.append(score_list)\n",
    "    \n",
    "os_report = pd.DataFrame(np.array(score_array),\n",
    "columns=['Algorithm', 'Accuracy', 'Recall', 'F1 Score', 'ROC AUC'])\n",
    "\n",
    "os_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm Accuracy Recall F1 Score ROC AUC\n",
       "0        Decision Tree      0.8    0.6     0.75     0.8\n",
       "1                  SVM     0.88   0.77     0.87    0.88\n",
       "2  Logistic Regression     0.92   0.88     0.92    0.92"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train[train.columns[2:-1]]\n",
    "y_train = train['Class']\n",
    "score_array = []\n",
    "\n",
    "bal_support = svm.SVC(class_weight ='balanced', random_state = 117)\n",
    "bal_dec_tree = tree.DecisionTreeClassifier(class_weight ='balanced', random_state = 117)\n",
    "bal_logreg =  LogisticRegression(class_weight ='balanced', random_state = 117)\n",
    "\n",
    "bal_classifiers = [bal_dec_tree, bal_support, bal_logreg]\n",
    "\n",
    "\n",
    "for i, clf in enumerate(bal_classifiers):\n",
    "    score_list = []\n",
    "    score_list.append(classifier_names[i])\n",
    "    clf.fit(x_train, y_train)\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    score_list.append(round(accuracy_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(recall_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(f1_score(y_true, clf_pred),2))\n",
    "    score_list.append(round(roc_auc_score(y_test, clf_pred),2))\n",
    "    score_array.append(score_list)\n",
    "\n",
    "bal_report = pd.DataFrame(np.array(score_array),\n",
    "columns=['Algorithm', 'Accuracy', 'Recall', 'F1 Score', 'ROC AUC'])\n",
    "\n",
    "bal_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_h2o(df,target,model_number):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function initiates an h2o cluster, converts\n",
    "    the dataframe to an h2o dataframe, and then runs\n",
    "    the autoML function to generate a list of optimal \n",
    "    predictor models, which are displayed on a scoreboard\n",
    "    \n",
    "    Arguments:\n",
    "        dataframe: Pandas dataframe. \n",
    "        target: String. Name of the predicted target\n",
    "        model_number: Int. Total number of models to run.\n",
    "        \n",
    "    Outputs:\n",
    "        prints Leader board of best performing models in the console\n",
    "        returns aml model\n",
    "    \"\"\"\n",
    "    #initiate cluser\n",
    "    h2o.init()\n",
    "    \n",
    "    #turn pandas to h2o dataframe\n",
    "    dataframe = h2o.H2OFrame(df)\n",
    "\n",
    "    #make sure the target is categorical\n",
    "    dataframe[target] = dataframe[target].asfactor()\n",
    "    \n",
    "    #Declare the x- and y- variables for the database. \n",
    "    #x-variables are predictor variables, and y-variable is what\n",
    "    #we wish to predict\n",
    "    x = dataframe.columns\n",
    "    y = target\n",
    "    \n",
    "    x.remove(y)\n",
    "\n",
    "    #Pull the training and test data out at a 80/20 split.\n",
    "    train, test, val = dataframe.split_frame(ratios=[.8, .1])\n",
    "    \n",
    "    # Run AutoML for N base models (limited to 1 hour max runtime by default); set the metric to AUC\n",
    "    aml = H2OAutoML(max_models=model_number,  sort_metric = 'AUC', seed=117)\n",
    "    aml.train(x=x, y=y, training_frame=train, validation_frame = val)\n",
    "\n",
    "    # View the AutoML Leaderboard\n",
    "    lb = aml.leaderboard\n",
    "    print(lb.head(rows=lb.nrows))\n",
    "    \n",
    "    #returns the h2o aml models\n",
    "    return aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the function\n",
    "h2o_aml = run_h2o(os_train, 'Class', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describes the leading model along with various metrics and confusion matrix\n",
    "h2o_aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get performance on test data\n",
    "test_h2o = h2o.H2OFrame(test)\n",
    "h2o_aml.leader.model_performance(test_data=test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_auc_roc(clf, x_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    fpr, tpr, thres = roc_curve(y_test, y_pred)\n",
    "    auc= roc_auc_score(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr, label='AUC ROC Cruve')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of H2O AutoML on SMOTE Data\n",
    "It seems the models most likely overfitted on training data. Precision and accuracy seem good, but this is definitely inflated since the number of fraudulent cases in the test file are just so scarce. This is reflected in the recall score of .56\n",
    "\n",
    "H2O has its own oversampling parameter, so lets see how it fares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien_Nguyen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_85a2 was not closed properly.\n"
     ]
    }
   ],
   "source": [
    "#shut down the previous cluster\n",
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_h2o(df,target,model_number):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function initiates an h2o cluster, converts\n",
    "    the dataframe to an h2o dataframe, and then runs\n",
    "    the autoML function to generate a list of optimal \n",
    "    predictor models, which are displayed on a scoreboard\n",
    "    \n",
    "    Arguments:\n",
    "        dataframe: Pandas dataframe. \n",
    "        target: String. Name of the predicted target\n",
    "        model_number: Int. Total number of models to run.\n",
    "        \n",
    "    Outputs:\n",
    "        prints Leader board of best performing models in the console\n",
    "        returns aml model\n",
    "    \"\"\"\n",
    "    \n",
    "    h2o.init()\n",
    "\n",
    "    dataframe = h2o.H2OFrame(df)\n",
    "    \n",
    "    dataframe[target] = dataframe[target].asfactor()\n",
    "    \n",
    "    #Declare the x- and y- variables for the database. \n",
    "    #x-variables are predictor variables, and y-variable is what\n",
    "    #we wish to predict\n",
    "    x = dataframe.columns\n",
    "    y = target\n",
    "    \n",
    "    x.remove(y)\n",
    "\n",
    "    #Pull the training and test data out at a 80/20 split.\n",
    "    train, test, val = dataframe.split_frame(ratios=[.8, .1])\n",
    "    \n",
    "    # Run AutoML for 20 base models (limited to 1 hour max runtime by default); set balance classes to True\n",
    "    aml = H2OAutoML(max_models=model_number,  sort_metric = 'AUC', balance_classes =True, seed=117)\n",
    "    aml.train(x=x, y=y, training_frame=train, validation_frame = val)\n",
    "\n",
    "    # View the AutoML Leaderboard\n",
    "    lb = aml.leaderboard\n",
    "    print(lb.head(rows=lb.nrows))\n",
    "    \n",
    "    return aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.7+8-LTS, mixed mode)\n",
      "  Starting server from C:\\Users\\Thien_Nguyen\\anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\THIEN_~1\\AppData\\Local\\Temp\\tmpey8xgjfb\n",
      "  JVM stdout: C:\\Users\\THIEN_~1\\AppData\\Local\\Temp\\tmpey8xgjfb\\h2o_Thien_Nguyen_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\THIEN_~1\\AppData\\Local\\Temp\\tmpey8xgjfb\\h2o_Thien_Nguyen_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Thien_Nguyen_drtb2y</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.973 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.2\n",
       "H2O_cluster_version_age:    9 days\n",
       "H2O_cluster_name:           H2O_from_python_Thien_Nguyen_drtb2y\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.973 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |\n",
      "16:46:57.338: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
      "16:46:57.356: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">   logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">        mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_4_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.995546</td><td style=\"text-align: right;\">0.00475649</td><td style=\"text-align: right;\">0.951953</td><td style=\"text-align: right;\">             0.0424852</td><td style=\"text-align: right;\">0.0223453</td><td style=\"text-align: right;\">0.000499311</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.992612</td><td style=\"text-align: right;\">0.00461577</td><td style=\"text-align: right;\">0.945644</td><td style=\"text-align: right;\">             0.0509349</td><td style=\"text-align: right;\">0.0232788</td><td style=\"text-align: right;\">0.000541905</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.991536</td><td style=\"text-align: right;\">0.00458362</td><td style=\"text-align: right;\">0.94548 </td><td style=\"text-align: right;\">             0.0467475</td><td style=\"text-align: right;\">0.0229005</td><td style=\"text-align: right;\">0.000524434</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.989422</td><td style=\"text-align: right;\">0.00398139</td><td style=\"text-align: right;\">0.951965</td><td style=\"text-align: right;\">             0.0212863</td><td style=\"text-align: right;\">0.0232872</td><td style=\"text-align: right;\">0.000542295</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200508_164657_model_1         </td><td style=\"text-align: right;\">0.989099</td><td style=\"text-align: right;\">0.00531765</td><td style=\"text-align: right;\">0.948948</td><td style=\"text-align: right;\">             0.0340481</td><td style=\"text-align: right;\">0.0228042</td><td style=\"text-align: right;\">0.000520034</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.985846</td><td style=\"text-align: right;\">0.00467995</td><td style=\"text-align: right;\">0.822095</td><td style=\"text-align: right;\">             0.127406 </td><td style=\"text-align: right;\">0.0323798</td><td style=\"text-align: right;\">0.00104845 </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200508_164657              </td><td style=\"text-align: right;\">0.985647</td><td style=\"text-align: right;\">0.0119996 </td><td style=\"text-align: right;\">0.870157</td><td style=\"text-align: right;\">             0.0385351</td><td style=\"text-align: right;\">0.0321247</td><td style=\"text-align: right;\">0.001032   </td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.984958</td><td style=\"text-align: right;\">0.00485707</td><td style=\"text-align: right;\">0.944418</td><td style=\"text-align: right;\">             0.0720838</td><td style=\"text-align: right;\">0.0225069</td><td style=\"text-align: right;\">0.000506559</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.982854</td><td style=\"text-align: right;\">0.0109205 </td><td style=\"text-align: right;\">0.950658</td><td style=\"text-align: right;\">             0.0213487</td><td style=\"text-align: right;\">0.0424588</td><td style=\"text-align: right;\">0.00180275 </td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200508_164657                       </td><td style=\"text-align: right;\">0.982835</td><td style=\"text-align: right;\">0.0111887 </td><td style=\"text-align: right;\">0.952306</td><td style=\"text-align: right;\">             0.0213487</td><td style=\"text-align: right;\">0.0427954</td><td style=\"text-align: right;\">0.00183145 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200508_164657   </td><td style=\"text-align: right;\">0.970181</td><td style=\"text-align: right;\">0.0029351 </td><td style=\"text-align: right;\">0.911555</td><td style=\"text-align: right;\">             0.0762962</td><td style=\"text-align: right;\">0.0217578</td><td style=\"text-align: right;\">0.000473401</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200508_164657</td><td style=\"text-align: right;\">0.96886 </td><td style=\"text-align: right;\">0.00289467</td><td style=\"text-align: right;\">0.924451</td><td style=\"text-align: right;\">             0.0720714</td><td style=\"text-align: right;\">0.0215892</td><td style=\"text-align: right;\">0.000466092</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "h2o_aml = run_h2o(train, 'Class', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0008765146758255358\n",
      "RMSE: 0.029605990539509665\n",
      "LogLoss: 0.013648360645228723\n",
      "Mean Per-Class Error: 0.20966449674511767\n",
      "AUC: 0.7628242363545318\n",
      "AUCPR: 0.5370671929248207\n",
      "Gini: 0.5256484727090636\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.00079726206533019: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9985.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/9985.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>(7.0/15.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>(7.0/10000.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1   Error            Rate\n",
       "0      0  9985.0  0.0     0.0    (0.0/9985.0)\n",
       "1      1     7.0  8.0  0.4667      (7.0/15.0)\n",
       "2  Total  9992.0  8.0  0.0007   (7.0/10000.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>7.972621e-04</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>7.972621e-04</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>7.972621e-04</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>7.972621e-04</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>1.233421e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>7.972621e-04</td>\n",
       "      <td>0.730041</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>1.743218e-08</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>1.743218e-08</td>\n",
       "      <td>0.790336</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>9985.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>5.722093e-09</td>\n",
       "      <td>9985.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>1.233421e-08</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>9.903052e-01</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>5.722093e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>1.233421e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric     threshold        value    idx\n",
       "0                        max f1  7.972621e-04     0.695652    7.0\n",
       "1                        max f2  7.972621e-04     0.588235    7.0\n",
       "2                  max f0point5  7.972621e-04     0.851064    7.0\n",
       "3                  max accuracy  7.972621e-04     0.999300    7.0\n",
       "4                 max precision  9.903052e-01     1.000000    0.0\n",
       "5                    max recall  1.233421e-08     1.000000  339.0\n",
       "6               max specificity  9.903052e-01     1.000000    0.0\n",
       "7              max absolute_mcc  7.972621e-04     0.730041    7.0\n",
       "8    max min_per_class_accuracy  1.743218e-08     0.600000  173.0\n",
       "9   max mean_per_class_accuracy  1.743218e-08     0.790336  173.0\n",
       "10                      max tns  9.903052e-01  9985.000000    0.0\n",
       "11                      max fns  9.903052e-01    14.000000    0.0\n",
       "12                      max fps  5.722093e-09  9985.000000  399.0\n",
       "13                      max tps  1.233421e-08    15.000000  339.0\n",
       "14                      max tnr  9.903052e-01     1.000000    0.0\n",
       "15                      max fnr  9.903052e-01     0.933333    0.0\n",
       "16                      max fpr  5.722093e-09     1.000000  399.0\n",
       "17                      max tpr  1.233421e-08     1.000000  339.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  0.15 %, avg score:  0.05 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>2.260419e-08</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>5.410931e-02</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.054109</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>5233.333333</td>\n",
       "      <td>5233.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>1.743310e-08</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.931621e-08</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>566.666667</td>\n",
       "      <td>2900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>1.517341e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.619059e-08</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>1.470287e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.491806e-08</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.421021e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.444032e-08</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.299733e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.331535e-08</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>1.233657e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.252912e-08</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>1.233635e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.781641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233640e-08</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>178.164117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>1.233632e-08</td>\n",
       "      <td>1.536098</td>\n",
       "      <td>2.424242</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>1.233633e-08</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>53.609831</td>\n",
       "      <td>142.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>1.233628e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.831045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233629e-08</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>83.104453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>1.233619e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.464909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233623e-08</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>46.490878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.6008</td>\n",
       "      <td>1.233598e-08</td>\n",
       "      <td>0.665336</td>\n",
       "      <td>1.331558</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.233605e-08</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-33.466401</td>\n",
       "      <td>33.155792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>1.233585e-08</td>\n",
       "      <td>0.670017</td>\n",
       "      <td>1.237565</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>1.233592e-08</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>-32.998325</td>\n",
       "      <td>23.756485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>1.233547e-08</td>\n",
       "      <td>0.664673</td>\n",
       "      <td>1.165792</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.233572e-08</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>-33.532735</td>\n",
       "      <td>16.579232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.233387e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.233496e-08</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>3.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.722093e-09</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.226983e-08</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0         1                    0.0100     2.260419e-08  53.333333   \n",
       "1         2                    0.0200     1.743310e-08   6.666667   \n",
       "2         3                    0.0300     1.517341e-08   0.000000   \n",
       "3         4                    0.0400     1.470287e-08   0.000000   \n",
       "4         5                    0.0500     1.421021e-08   0.000000   \n",
       "5         6                    0.1000     1.299733e-08   0.000000   \n",
       "6         7                    0.1500     1.233657e-08   0.000000   \n",
       "7         8                    0.2157     1.233635e-08   0.000000   \n",
       "8         9                    0.3025     1.233632e-08   1.536098   \n",
       "9        10                    0.4005     1.233628e-08   0.000000   \n",
       "10       11                    0.5006     1.233619e-08   0.000000   \n",
       "11       12                    0.6008     1.233598e-08   0.665336   \n",
       "12       13                    0.7003     1.233585e-08   0.670017   \n",
       "13       14                    0.8006     1.233547e-08   0.664673   \n",
       "14       15                    0.9000     1.233387e-08   0.000000   \n",
       "15       16                    1.0000     5.722093e-09   0.666667   \n",
       "\n",
       "    cumulative_lift  response_rate         score  cumulative_response_rate  \\\n",
       "0         53.333333       0.080000  5.410931e-02                  0.080000   \n",
       "1         30.000000       0.010000  1.931621e-08                  0.045000   \n",
       "2         20.000000       0.000000  1.619059e-08                  0.030000   \n",
       "3         15.000000       0.000000  1.491806e-08                  0.022500   \n",
       "4         12.000000       0.000000  1.444032e-08                  0.018000   \n",
       "5          6.000000       0.000000  1.331535e-08                  0.009000   \n",
       "6          4.000000       0.000000  1.252912e-08                  0.006000   \n",
       "7          2.781641       0.000000  1.233640e-08                  0.004172   \n",
       "8          2.424242       0.002304  1.233633e-08                  0.003636   \n",
       "9          1.831045       0.000000  1.233629e-08                  0.002747   \n",
       "10         1.464909       0.000000  1.233623e-08                  0.002197   \n",
       "11         1.331558       0.000998  1.233605e-08                  0.001997   \n",
       "12         1.237565       0.001005  1.233592e-08                  0.001856   \n",
       "13         1.165792       0.000997  1.233572e-08                  0.001749   \n",
       "14         1.037037       0.000000  1.233496e-08                  0.001556   \n",
       "15         1.000000       0.001000  1.226983e-08                  0.001500   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.054109      0.533333                 0.533333  5233.333333   \n",
       "1           0.027055      0.066667                 0.600000   566.666667   \n",
       "2           0.018036      0.000000                 0.600000  -100.000000   \n",
       "3           0.013527      0.000000                 0.600000  -100.000000   \n",
       "4           0.010822      0.000000                 0.600000  -100.000000   \n",
       "5           0.005411      0.000000                 0.600000  -100.000000   \n",
       "6           0.003607      0.000000                 0.600000  -100.000000   \n",
       "7           0.002509      0.000000                 0.600000  -100.000000   \n",
       "8           0.001789      0.133333                 0.733333    53.609831   \n",
       "9           0.001351      0.000000                 0.733333  -100.000000   \n",
       "10          0.001081      0.000000                 0.733333  -100.000000   \n",
       "11          0.000901      0.066667                 0.800000   -33.466401   \n",
       "12          0.000773      0.066667                 0.866667   -32.998325   \n",
       "13          0.000676      0.066667                 0.933333   -33.532735   \n",
       "14          0.000601      0.000000                 0.933333  -100.000000   \n",
       "15          0.000541      0.066667                 1.000000   -33.333333   \n",
       "\n",
       "    cumulative_gain  \n",
       "0       5233.333333  \n",
       "1       2900.000000  \n",
       "2       1900.000000  \n",
       "3       1400.000000  \n",
       "4       1100.000000  \n",
       "5        500.000000  \n",
       "6        300.000000  \n",
       "7        178.164117  \n",
       "8        142.424242  \n",
       "9         83.104453  \n",
       "10        46.490878  \n",
       "11        33.155792  \n",
       "12        23.756485  \n",
       "13        16.579232  \n",
       "14         3.703704  \n",
       "15         0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_h2o = h2o.H2OFrame(test)\n",
    "h2o_aml.leader.model_performance(test_data=test_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling via H2O doesn't solve the issue either since overfitting is still occurring. However, it is difficult to ascertain a high recall exclusively since there are only 15 cases of fraudulent behavior in the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 1.0247461795806885 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.26402807235717773 seconds\n",
      "\n",
      "You have no test dataset !\n",
      "\n",
      "> Number of common features : 30\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 0\n",
      "> Number of numerical features: 30\n",
      "> Number of training samples : 59753\n",
      "> Number of test samples : 0\n",
      "\n",
      "> You have no missing values on train set...\n",
      "\n",
      "> Task : classification\n",
      "0.0    59590\n",
      "1.0      163\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "encoding target ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A classification example using mlbox.\"\"\"\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"train.csv\", \"test.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"Class\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.900773286819458 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.21503233909606934 seconds\n",
      "\n",
      "You have no test dataset !\n",
      "\n",
      "> Number of common features : 30\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 0\n",
      "> Number of numerical features: 30\n",
      "> Number of training samples : 59753\n",
      "> Number of test samples : 0\n",
      "\n",
      "> You have no missing values on train set...\n",
      "\n",
      "> Task : classification\n",
      "0.0    59590\n",
      "1.0      163\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "encoding target ...\n",
      "\n",
      "You have no test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien_Nguyen\\AppData\\Roaming\\Python\\Python37\\site-packages\\mlbox\\optimisation\\optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n",
      "\n",
      "MEAN SCORE : recall = 0.8526515151515153\n",
      "VARIANCE : 0.04168646223977218 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.8484848484848485, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 7.021338701248169 seconds\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}     \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.0930825565088684}\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8162878787878789              \n",
      "VARIANCE : 0.08561569736587658 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.6666666666666666, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 26.142309188842773 seconds                  \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.0501821506007261}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8526515151515153                                         \n",
      "VARIANCE : 0.04168646223977218 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.8484848484848485, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 24.27538824081421 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                   \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1170651447689331}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8162878787878789                                         \n",
      "VARIANCE : 0.08561569736587658 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.6666666666666666, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 22.281484603881836 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                   \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2218131247290439}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8524621212121213                                         \n",
      "VARIANCE : 0.053529844151426725 (fold 1 = 0.8484848484848485, fold 2 = 0.9393939393939394, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.78125)\n",
      "CPU time: 22.28677749633789 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                   \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.011233255696714326}      \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8162878787878789                                         \n",
      "VARIANCE : 0.08561569736587658 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.6666666666666666, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 23.639620542526245 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2846303165901328}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8401515151515152                                         \n",
      "VARIANCE : 0.041921568783776786 (fold 1 = 0.8484848484848485, fold 2 = 0.9090909090909091, fold 3 = 0.8181818181818182, fold 4 = 0.84375, fold 5 = 0.78125)\n",
      "CPU time: 22.377958297729492 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                   \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.15171163315134917}       \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.840340909090909                                          \n",
      "VARIANCE : 0.03668380203164314 (fold 1 = 0.8484848484848485, fold 2 = 0.8787878787878788, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.78125)\n",
      "CPU time: 22.023898601531982 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.12741645337182295}       \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8162878787878789                                         \n",
      "VARIANCE : 0.08561569736587658 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.6666666666666666, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 23.40553379058838 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.17691017275678642}       \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.827840909090909                                          \n",
      "VARIANCE : 0.04342204576905046 (fold 1 = 0.8787878787878788, fold 2 = 0.8484848484848485, fold 3 = 0.8181818181818182, fold 4 = 0.84375, fold 5 = 0.75)\n",
      "CPU time: 27.15331506729126 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}      \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06706370121108432}       \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.840340909090909                                          \n",
      "VARIANCE : 0.03668380203164314 (fold 1 = 0.8484848484848485, fold 2 = 0.8787878787878788, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.78125)\n",
      "CPU time: 21.927029848098755 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}       \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1711423310765723}         \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.840340909090909                                           \n",
      "VARIANCE : 0.03668380203164314 (fold 1 = 0.8484848484848485, fold 2 = 0.8787878787878788, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.78125)\n",
      "CPU time: 24.54717493057251 seconds                                               \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}       \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                  \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.23840821512905785}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.834090909090909                                           \n",
      "VARIANCE : 0.05454545454545453 (fold 1 = 0.8181818181818182, fold 2 = 0.9090909090909091, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.75)\n",
      "CPU time: 25.464221715927124 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}       \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                    \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.20807626960095119}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.8219696969696969                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIANCE : 0.03615886949249391 (fold 1 = 0.7878787878787878, fold 2 = 0.8787878787878788, fold 3 = 0.8181818181818182, fold 4 = 0.84375, fold 5 = 0.78125)\n",
      "CPU time: 22.79263949394226 seconds                                               \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}       \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18296197102936268}        \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.846590909090909                                           \n",
      "VARIANCE : 0.04399079412627626 (fold 1 = 0.8484848484848485, fold 2 = 0.8787878787878788, fold 3 = 0.8181818181818182, fold 4 = 0.90625, fold 5 = 0.78125)\n",
      "CPU time: 20.902161121368408 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}       \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                    \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2090013117316152}         \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : recall = 0.834090909090909                                           \n",
      "VARIANCE : 0.05454545454545453 (fold 1 = 0.8181818181818182, fold 2 = 0.9090909090909091, fold 3 = 0.8181818181818182, fold 4 = 0.875, fold 5 = 0.75)\n",
      "CPU time: 22.24418568611145 seconds                                               \n",
      "100%|██████████| 15/15 [05:52<00:00, 23.51s/trial, best loss: -0.8526515151515153]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'random_projection', 'est__max_depth': 7, 'fs__threshold': 0.0501821506007261, 'ne__numerical_strategy': 0}\n",
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien_Nguyen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 5.294022798538208 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thien_Nguyen\\AppData\\Roaming\\Python\\Python37\\site-packages\\mlbox\\prediction\\predictor.py:392: UserWarning: Unable to get feature importances !\n",
      "  warnings.warn(\"Unable to get feature importances !\")\n",
      "C:\\Users\\Thien_Nguyen\\AppData\\Roaming\\Python\\Python37\\site-packages\\mlbox\\prediction\\predictor.py:405: UserWarning: You have no test dataset. Cannot predict !\n",
      "  warnings.warn(\"You have no test dataset. Cannot predict !\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlbox.prediction.predictor.Predictor at 0x1e20b6e1048>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"A classification example using mlbox.\"\"\"\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"train.csv\", \"test.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"Class\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "# Declare an optimiser. Scoring possibilities for classification lie in :\n",
    "# {\"accuracy\", \"roc_auc\", \"f1\", \"neg_log_loss\", \"precision\", \"recall\"}\n",
    "opt = Optimiser(scoring='recall', n_folds=5)\n",
    "opt.evaluate(None, data)\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {'ne__numerical_strategy': {\"search\": \"choice\", \"space\": [0]},\n",
    "         'ce__strategy': {\"search\": \"choice\",\n",
    "                          \"space\": [\"label_encoding\",\n",
    "                                    \"random_projection\",\n",
    "                                    \"entity_embedding\"]},\n",
    "         'fs__threshold': {\"search\": \"uniform\",\n",
    "                           \"space\": [0.01, 0.3]},\n",
    "         'est__max_depth': {\"search\": \"choice\",\n",
    "                            \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "         }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "\n",
    "# Make prediction and save the results in save folder.\n",
    "prd = Predictor()\n",
    "prd.fit_predict(best, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. H2O.ai. H2O AutoML, June 2017. URL http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html. H2O version 3.30.0.1.\n",
    "2. https://mlbox.readthedocs.io/en/latest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "\n",
    "#initiate cluser\n",
    "h2o.init()\n",
    "    \n",
    "#turn pandas to h2o dataframe\n",
    "dataframe = h2o.H2OFrame(df)\n",
    "\n",
    "#make sure the target is categorical\n",
    "dataframe[target] = dataframe[target].asfactor()\n",
    "    \n",
    "#Declare the x- and y- variables for the database. \n",
    "#x-variables are predictor variables, and y-variable is what\n",
    "#we wish to predict\n",
    "x = dataframe.columns\n",
    "y = target\n",
    "\n",
    "#remove the target feature from the x columns\n",
    "x.remove(y)\n",
    "\n",
    "#Pull the training and test data out at a 80/20 split.\n",
    "train, test = dataframe.split_frame(ratios=[.8, .2])\n",
    "    \n",
    "# Run AutoML for N base models (limited to 1 hour max runtime by default); set the metric to AUC\n",
    "aml = H2OAutoML(max_models=model_number,  sort_metric = 'AUC', seed=117)\n",
    "aml.train(x=x, y=y, training_frame=train, validation_frame = val)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_h2o = h2o.H2OFrame(test)\n",
    "h2o_aml.leader.model_performance(test_data=test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "#Run PCA on the scaled features\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "#plot a cumulative plot of explain variance to threshold\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = np.arange(len(cumsum))+1\n",
    "\n",
    "plt.plot(dim,cumsum,'-',lw=3);\n",
    "\n",
    "plt.xlabel('# of Components')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.title('Selecting the right number of Components')\n",
    "\n",
    "plt.ylim([0,1.1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
